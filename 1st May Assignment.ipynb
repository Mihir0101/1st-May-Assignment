{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "792a207b-bbd4-4b0f-b24d-5444bacdb72a",
   "metadata": {},
   "source": [
    "# 1st May Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f6f5c2-45f5-4410-91a4-512c30c29053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f49168f-08fc-4f81-8534-87b806eb9fc0",
   "metadata": {},
   "source": [
    "## Q1. What is a contingency matrix, and how is it used to evaluate the performance of a classification model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a9e32a-b5b3-49ce-b7ef-5a9fb68cba8c",
   "metadata": {},
   "source": [
    "Contingency matrix is also known as confusion matrix.\n",
    "\n",
    "It a table that summarizes the performance of a classification model. \n",
    "\n",
    "It provides a detailed breakdown of predicted and actual class assignments.\n",
    "\n",
    "The matrix is especially useful for binary classification problems but can be extended to multi-class scenarios.\n",
    "\n",
    "Key Components : TP,TN,FP,FN\n",
    " \n",
    "* Confusion matrix is used to evaluate the different performance matrics like,\n",
    "\n",
    "Accuracy\n",
    "\n",
    "Precision\n",
    "\n",
    "Recall\n",
    "\n",
    "F-Score Beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1efcba6-fa9e-4636-b920-76013b508c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3cece624-5dd1-42e3-aa9f-ee2fa238c222",
   "metadata": {},
   "source": [
    "## Q2. How is a pair confusion matrix different from a regular confusion matrix, and why might it be useful in certain situations?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8c2ea2-1bed-4c40-908d-22dbbac53167",
   "metadata": {},
   "source": [
    "A pair confusion matrix is a variation of the traditional confusion matrix that is specifically designed for evaluating the performance of binary classification models in situations where pairs of classes are of particular interest. \n",
    "\n",
    "* Usefulness\n",
    "\n",
    "Focus on specific class pair.\n",
    "\n",
    "In imbalanced datasets where one class is significantly more prevalent than the other, traditional confusion matrices might not adequately capture the performance for the minority class. \n",
    "\n",
    "Pair confusion matrices allow for a customized evaluation tailored to the specific goals and priorities of a given classification task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807f37a8-7ab2-4deb-b608-b6f8611dd410",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30be9b48-d41e-4357-8dd5-748676f7e389",
   "metadata": {},
   "source": [
    "## Q3. What is an extrinsic measure in the context of natural language processing, and how is it typically used to evaluate the performance of language models?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9eb5d4-4ad0-40bc-a05d-1126f5a38cea",
   "metadata": {},
   "source": [
    "In the context of natural language processing (NLP), an extrinsic measure is an evaluation metric that assesses the performance of a language model based on its performance in a downstream task or application.\n",
    "\n",
    "* How is it typically used?\n",
    "\n",
    "Language models are often designed to perform specific tasks such as sentiment analysis, named entity recognition, machine translation, or text summarization. Extrinsic measures evaluate how well the language model performs in these downstream tasks.\n",
    "\n",
    "Evaluation metrics for extrinsic measures are task-specific and depend on the nature of the application. For example, accuracy, precision, recall, F1 score, BLEU score, or ROUGE score might be used based on the task.\n",
    "\n",
    "The goal of using extrinsic measures is to gauge how well a language model generalizes to real-world scenarios. It provides insights into the practical utility of the model in applications that end-users care about.\n",
    "\n",
    "Ultimately, the success of an NLP model is often measured by user satisfaction in real-world applications. Extrinsic measures help bridge the gap between model performance in controlled settings and its impact on user experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83b457a-5b60-4a57-a671-68289d0a85ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1056b77c-4741-4f29-a26c-89c4ee555418",
   "metadata": {},
   "source": [
    "## Q4. What is an intrinsic measure in the context of machine learning, and how does it differ from an extrinsic measure?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d3cbfc-b145-4535-a437-b2fedd075c0d",
   "metadata": {},
   "source": [
    "* Intrinsic Measure\n",
    "\n",
    "An intrinsic measure evaluates specific aspects of a model in isolation, often without considering its performance in real-world applications or downstream tasks. These measures typically assess the model's internal qualities, capabilities, or characteristics.\n",
    "\n",
    "* How it is differ from extrinsic\n",
    "\n",
    "Focus\n",
    "\n",
    "Task Relevance\n",
    "\n",
    "Real-World Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14aaf077-879f-4c7a-8481-b0a2632f8ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01b5cd54-d7a7-4c91-a087-e48c3ec027c3",
   "metadata": {},
   "source": [
    "## Q5. What is the purpose of a confusion matrix in machine learning, and how can it be used to identify strengths and weaknesses of a model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10978d2-a14f-4663-b668-f7fff89b78e5",
   "metadata": {},
   "source": [
    "A confusion matrix is a fundamental tool in machine learning for evaluating the performance of a classification model.\n",
    "\n",
    "* How to it identify strengths and weaknesses\n",
    "\n",
    "A model may achieve high accuracy but struggle with imbalanced classes. The confusion matrix helps reveal whether the model is disproportionately predicting the majority class.\n",
    "\n",
    "Understanding the consequences of false positives and false negatives is crucial. \n",
    "\n",
    "Sensitivity (recall) and specificity are essential metrics for evaluating model performance. The confusion matrix provides the basis for computing these metrics, offering insights into the model's ability to capture true positives and true negatives.\n",
    "\n",
    "Examining the trade-offs between precision and recall (sensitivity) helps in understanding the model's behavior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fb8b54-8d07-442d-9ac2-46b991b6d8ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd8c374c-9a6a-4555-b003-664813bff864",
   "metadata": {},
   "source": [
    "## Q6. What are some common intrinsic measures used to evaluate the performance of unsupervised learning algorithms, and how can they be interpreted?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66ae8d3-2c02-4222-a708-cc71d57970f2",
   "metadata": {},
   "source": [
    "Silhouette Score\n",
    "\n",
    "Devies-Bouldin Index\n",
    "\n",
    "Calinski-Harabasz Index\n",
    "\n",
    "Dunn Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b08314-1565-453d-88b2-070b5483366b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc4ba6c2-a705-40b4-a513-0c08ef1338a7",
   "metadata": {},
   "source": [
    "## Q7. What are some limitations of using accuracy as a sole evaluation metric for classification tasks, and how can these limitations be addressed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d50072-f1a5-4b59-a8da-3554b7bb4d18",
   "metadata": {},
   "source": [
    "1.\n",
    "\n",
    "Limitation : In imbalanced datasets, where one class significantly outnumbers the others, accuracy can be misleading. \n",
    "\n",
    "Addressing :  Consider using other metrics such as precision, recall, F1 score, or the area under the receiver operating characteristic (ROC) curve, especially when dealing with imbalanced datasets.\n",
    "\n",
    "2.\n",
    "\n",
    "Limitation :  Accuracy might not reflect model performance accurately when dealing with skewed class distributions.\n",
    "\n",
    "Addressing : Utilize precision and recall metrics, as they provide insights into the model's ability to correctly identify positive instances (precision) and capture all positive instances (recall).\n",
    "\n",
    "3.\n",
    "\n",
    "Limitation : Accuracy treats false positives and false negatives equally, ignoring the consequences of different types of errors in various applications.\n",
    "\n",
    "Addressing: Examine precision and recall separately to gain a nuanced understanding of the model's performance in terms of false positives and false negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b655794a-f823-434f-ae9a-038b2c8a6c6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
